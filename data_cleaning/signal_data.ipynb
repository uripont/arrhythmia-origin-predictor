{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1a120b",
   "metadata": {},
   "source": [
    "In this notebook we want to go from raw data, to a filtered, organized and normalized dataset of ECGs, where we have pre-processed each to basically align it according to the R-peak near the 2-second mark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ae023c",
   "metadata": {},
   "source": [
    "First we load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da90ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pickle.load(open('../all_points_may_2024.pkl', 'rb'))\n",
    "data = pd.DataFrame(data).T\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d4b7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspecting the data, we see that ECGs are stored in the \"Structures\" column. A sample of its structure:\n",
    "\n",
    "# %%\n",
    "def unpack_structures(data):\n",
    "    rows = []\n",
    "    for patient_id, structures in data['Structures'].items():\n",
    "        if isinstance(structures, dict):\n",
    "            for anatomical_region, positions_dict in structures.items():\n",
    "                for position, ecg_dict in positions_dict.items():\n",
    "                    rows.append({\n",
    "                        'patient': patient_id,\n",
    "                        'anatomical region': anatomical_region,\n",
    "                        'position': position,\n",
    "                        'ecg': ecg_dict  # Este es el dict con las 12 derivaciones\n",
    "                    })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Supongamos que `data` es tu DataFrame original y 'Structures' es una columna\n",
    "result_df = unpack_structures(data)\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb37cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Lista de pacientes a eliminar \n",
    "patients_to_remove = ['P186', 'P173', 'P268', 'P164', 'P295', 'P185']\n",
    "\n",
    "# Elimina de 'data'\n",
    "data = data.drop(patients_to_remove, errors='ignore')\n",
    "\n",
    "# Elimina de 'result_df'\n",
    "result_df = result_df[~result_df['patient'].isin(patients_to_remove)]\n",
    "\n",
    "\n",
    "# %%\n",
    "display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b604814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# en el seguent codi seprem en 12 columnes diferents les 12 derviacions es a dir que obtenim un dataframe and patient, anatomical region, posiiton , I, II, III....\n",
    "\n",
    "# %%\n",
    "def unpack_structures_expand_ecg(data):\n",
    "    rows = []\n",
    "    for patient_id, structures in data['Structures'].items():\n",
    "        if isinstance(structures, dict):\n",
    "            for anatomical_region, positions_dict in structures.items():\n",
    "                for position, ecg_dict in positions_dict.items():\n",
    "                    # Crear fila base\n",
    "                    row = {\n",
    "                        'patient': patient_id,\n",
    "                        'anatomical region': anatomical_region,\n",
    "                        'position': position,\n",
    "                    }\n",
    "                    # Añadir cada derivación del ecg como columna\n",
    "                    if isinstance(ecg_dict, dict):\n",
    "                        row.update(ecg_dict)\n",
    "                    rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "result_df_leads = unpack_structures_expand_ecg(data)\n",
    "display(result_df_leads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdeb9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "result_df__leads_encoded = pd.get_dummies(result_df_leads, columns=['anatomical region', 'position'])\n",
    "display(result_df__leads_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512e781e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Selecciona las columnas de las 12 derivaciones y el identificador de paciente\n",
    "lead_columns = ['patient', 'I', 'II', 'III', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "df_leads_only = result_df_leads[lead_columns].copy()\n",
    "display(df_leads_only)\n",
    "\n",
    "\n",
    "# %%\n",
    "'''# Expand each lead's list of samples into separate columns\n",
    "lead_names = ['I', 'II', 'III', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "\n",
    "# Stack all leads horizontally for each row\n",
    "expanded_leads = []\n",
    "column_names = []\n",
    "\n",
    "for lead in lead_names:\n",
    "    lead_matrix = np.stack(df_leads_only[lead].values)\n",
    "    expanded_leads.append(lead_matrix)\n",
    "    column_names.extend([f\"{lead}_{i}\" for i in range(lead_matrix.shape[1])])\n",
    "\n",
    "# Concatenate all leads horizontally\n",
    "signal_matrix = np.hstack(expanded_leads)\n",
    "\n",
    "# Create a DataFrame with the expanded columns\n",
    "expanded_df = pd.DataFrame(signal_matrix, columns=column_names)\n",
    "\n",
    "# Add the patient column back\n",
    "expanded_df.insert(0, 'patient', df_leads_only['patient'].values)\n",
    "display(expanded_df)'''\n",
    "\n",
    "# %% [markdown]\n",
    "# Ara segmentarem els ecgs per poder fer l'alignment\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/guillermo-jimenez/sak.git\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5675509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "#Example with ECG segmentation\n",
    "\n",
    "import torch\n",
    "import sak\n",
    "from functools import partial\n",
    "import math\n",
    "import scipy as sp\n",
    "import skimage\n",
    "import skimage.util\n",
    "from typing import List,Tuple\n",
    "import numpy as np\n",
    "models_ECG = [\n",
    "    torch.load(f\"modelos/model.{i+1}\") for i in range(5)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4888589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Predict_ecg stroing all segmentations\n",
    "\n",
    "# %%\n",
    "def predict_ecg(ecg: np.ndarray, fs: float, model: List[torch.nn.Module],\n",
    "                window_size: int = 2048, stride: int = 256, threshold_ensemble: float = 0.5,\n",
    "                thr_dice=0.9, percentile=95, ptg_voting = 0.5, batch_size = 16,\n",
    "                normalize=True, norm_threshold: float = 1e-6, filter = True) -> np.ndarray:\n",
    "    \"\"\"This function is used to delineate an ECG recording of arbitrary size ('ecg' variable, SAMPLES x LEADS)\n",
    "    and to obtain the fiducials for the P, QRS and T segments as a binary mask of shape 3 x SAMPLES.\n",
    "\n",
    "    Inputs:\n",
    "    ecg                <- some array, e.g. shape 198484 x 12\n",
    "    fs                 <- sampling frequency, e.g. 1000Hz. Will downsample to 250Hz for the AI model to work\n",
    "    model              <- list of segmentation models for the ensemble\n",
    "    window_size        <- the \"chunk\" size that will be processed at a time of the input ecg (e.g., in the example,\n",
    "                          2048 samples out of the 198484 samples of the ECG)\n",
    "    stride             <- the \"stride\" parameter allows for some overlap between the windows of the window_size\n",
    "    threshold_ensemble <- Percentage of voting for the AI ensemble [0-1]\n",
    "    thr_dice           <- Threshold for considering each sample as positive according to the Dice score\n",
    "    percentile         <- Percentile for the amplitude normalization\n",
    "    ptg_voting         <- Threshold for considering each sample as positive according to the Dice score\n",
    "    batch_size         <- Number of windows that fit in the batch\n",
    "    normalize          <- Boolean to indicate whether the ECG has to be normalized. In general, set this to True\n",
    "                          always, as the ECGs must have the amplitude of a normal sinus rhythm around amplitude of\n",
    "                          \"1\" to work, as that was the preprocessing for model training. Only change if a\n",
    "                          comparable pre-processing is performed\n",
    "    norm_threshold     <- Threshold for the normalization, to avoid passing baseline wander or noise as signal\n",
    "    filter             <- Filter the signal with a band-pass filter in [0.5-125] Hz\n",
    "    \"\"\"\n",
    "    # Preprocess signal\n",
    "    ecg = np.copy(ecg).squeeze()\n",
    "    if ecg.ndim == 0:\n",
    "        return np.array([])\n",
    "    elif ecg.ndim == 1:\n",
    "        ecg = ecg[:,None]\n",
    "    elif ecg.ndim == 2:\n",
    "        if ecg.shape[0] < ecg.shape[1]:\n",
    "            ecg = ecg.T\n",
    "    else:\n",
    "        raise ValueError(\"2 dims max allowed\")\n",
    "    ecg_250 = sak.signal.interpolate.interp1d(ecg,round(ecg.shape[0]*250/fs),axis=0)\n",
    "\n",
    "\n",
    "    # Pad if necessary\n",
    "    if ecg_250.shape[0] < window_size:\n",
    "        padding = math.ceil(ecg_250.shape[0]/window_size)*window_size-ecg_250.shape[0]\n",
    "        ecg_250 = np.pad(ecg_250,((0,padding),(0,0)),mode='edge')\n",
    "    if (ecg_250.shape[0]-window_size)%stride != 0:\n",
    "        padding = math.ceil((ecg_250.shape[0]-window_size)/stride)*stride-(ecg_250.shape[0]%window_size)\n",
    "        ecg_250 = np.pad(ecg_250,((0,padding),(0,0)),mode='edge')\n",
    "\n",
    "    # Get dimensions\n",
    "    N,L = ecg_250.shape\n",
    "\n",
    "    # (Optional) Normalize amplitudes\n",
    "    if normalize:\n",
    "        # Get ecg_250 when it's not flat zero\n",
    "        norm_signal = ecg_250[np.all(np.abs(np.diff(ecg_250,axis=0,append=0)) >= norm_threshold,axis=1),:]\n",
    "\n",
    "        # High pass filter normalized ecg_250 to avoid issues with baseline wander\n",
    "        norm_signal = sp.signal.filtfilt(*sp.signal.butter(2, 0.5/250., 'high'),norm_signal, axis=0)\n",
    "\n",
    "        # Compute amplitude for those segments\n",
    "        amplitude = np.array(sak.signal.moving_lambda(\n",
    "            norm_signal,\n",
    "            256,\n",
    "            partial(sak.signal.amplitude,axis=0),\n",
    "            axis=0\n",
    "        ))\n",
    "        amplitude = amplitude[np.all(amplitude > norm_threshold,axis=1),]\n",
    "        amplitude = np.percentile(amplitude, percentile, axis=0)\n",
    "\n",
    "        # Apply normalization\n",
    "        ecg_250 = ecg_250/amplitude[None,:]\n",
    "\n",
    "    # (Optional) Filter ecg_250\n",
    "    if filter:\n",
    "        ecg_250 = sp.signal.filtfilt(*sp.signal.butter(2,   0.5/250., 'high'),ecg_250,axis=0)\n",
    "        ecg_250 = sp.signal.filtfilt(*sp.signal.butter(2, 125.0/250.,  'low'),ecg_250,axis=0)\n",
    "        ecg_250 = sp.signal.lfilter(*sp.signal.iirnotch(50,20.0,250.),ecg_250,axis=0)\n",
    "        ecg_250 = sp.signal.lfilter(*sp.signal.iirnotch(60,20.0,250.),ecg_250,axis=0)\n",
    "\n",
    "    # Avoid issues with negative strides due to filtering:\n",
    "    if np.any(np.array(ecg_250.strides) < 0):\n",
    "        ecg_250 = ecg_250.copy()\n",
    "\n",
    "    # Data structure for computing the segmentation\n",
    "    windowed_signal = skimage.util.view_as_windows(ecg_250,(window_size,1),(stride,1))\n",
    "\n",
    "    # Flat batch shape\n",
    "    new_shape = (windowed_signal.shape[0]*windowed_signal.shape[1],*windowed_signal.shape[2:])\n",
    "    windowed_signal = np.reshape(windowed_signal,new_shape)\n",
    "\n",
    "    # Exchange channel position\n",
    "    windowed_signal = np.swapaxes(windowed_signal,1,2)\n",
    "\n",
    "    # Output structures\n",
    "    windowed_mask = np.zeros((windowed_signal.shape[0],3,windowed_signal.shape[-1]),dtype=int)\n",
    "\n",
    "    # Check device for segmentation\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Compute segmentation for all leads independently\n",
    "    with torch.no_grad():\n",
    "        if isinstance(model,list):\n",
    "            for m in model:\n",
    "                m = m.to(device)\n",
    "                for i in range(0,windowed_signal.shape[0],batch_size):\n",
    "                    inputs = {\"x\": torch.tensor(windowed_signal[i:i+batch_size]).float().to(device)}\n",
    "                    outputs = m(inputs)[\"sigmoid\"].cpu().detach().numpy()\n",
    "                    windowed_mask[i:i+batch_size] += outputs > thr_dice\n",
    "            windowed_mask = windowed_mask >= len(model)*threshold_ensemble\n",
    "        else:\n",
    "            model = model.to(device)\n",
    "            for i in range(0,windowed_signal.shape[0],batch_size):\n",
    "                inputs = {\"x\": torch.tensor(windowed_signal[i:i+batch_size]).to(device).float()}\n",
    "                outputs = model(inputs)[\"sigmoid\"].cpu().detach().numpy()\n",
    "                windowed_mask[i:i+batch_size] = outputs > thr_dice\n",
    "\n",
    "    # Retrieve mask as 1D\n",
    "    counter = np.zeros((N), dtype=int)\n",
    "    segmentation_250 = np.zeros((3,N))\n",
    "\n",
    "    # Iterate over windows\n",
    "    for i in range(0,windowed_mask.shape[0],L):\n",
    "        counter[(i//L)*stride:(i//L)*stride+window_size] += 1\n",
    "        segmentation_250[:,(i//L)*stride:(i//L)*stride+window_size] += windowed_mask[i:i+L].sum(0)\n",
    "    segmentation_250 = ((segmentation_250/counter) >= (ecg_250.shape[-1]*ptg_voting))\n",
    "\n",
    "    # Correct padding\n",
    "    segmentation_250 = segmentation_250[:,:-padding]\n",
    "\n",
    "    # Interpolate back to original sampling frequency\n",
    "    segmentation     = sak.signal.interpolate.interp1d(segmentation_250,ecg.shape[0],axis=-1,kind=\"nearest\")\n",
    "    # Crear vector de tiempo total\n",
    "    time_vector = np.linspace(0, ecg.shape[0]/fs, ecg.shape[0], endpoint=False)\n",
    "\n",
    "    # Crear vectores de tiempo segmentados para cada onda\n",
    "    time_QRS = time_vector[segmentation[1].astype(bool)]\n",
    "\n",
    "    return segmentation,time_QRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2561207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Segmentation por patient 23047\n",
    "\n",
    "# %%\n",
    "from sak.signal import StandardHeader\n",
    "ecg_signals1 = []\n",
    "for lead in StandardHeader:\n",
    "    ecg_signals1.append(df_leads_only[lead][23047])\n",
    "    \n",
    "ecg_signals1 = np.asarray(ecg_signals1).T\n",
    "print(ecg_signals1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f3d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# We filter the signal (code profe) and we apply the function predict_ecg.\n",
    "\n",
    "# %%\n",
    "#Apply the segmentation for a single record (make function to apply to multiple signals)\n",
    "fs = 1000\n",
    "fs_high,fs_low = 0.5,100.0\n",
    "ecg_250 = sak.signal.interpolate.interp1d(ecg_signals1,round(ecg_signals1.shape[0]*250/fs), axis=0).T\n",
    "ecg_250 = sp.signal.filtfilt(*sp.signal.butter(2, fs_high/250., 'high'), ecg_250, axis=-1)\n",
    "ecg_250 = sp.signal.filtfilt(*sp.signal.butter(2,  fs_low/250.,  'low'), ecg_250, axis=-1)\n",
    "\n",
    "segmentation_250, time_QRS= predict_ecg(ecg_250, 250., models_ECG, normalize=True, filter=False)\n",
    "\n",
    "# Print entire array without truncation\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "segmentation1 = sak.signal.interpolate.interp1d(segmentation_250, ecg_signals1.shape[0], axis=-1, kind=\"nearest\")\n",
    "\n",
    "# %% [markdown]\n",
    "# We print what the segmentation returns. It is a binarized array where 1 indicates the possible/correct location of the desired segmed. Segmentation 1 is composed by three arays where the first one indicates the locations of the P wave, the second array indicated the locations of the QRS complex and the last array indicates the lcoations of the waves T. \n",
    "print(segmentation1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import numpy as np\n",
    "# %% [markdown]\n",
    "# We plot the segmented signal\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(4,3)\n",
    "row = 0\n",
    "col = 0\n",
    "x = np.linspace(0,2.5,int(fs*2.5))\n",
    "for i,sig in enumerate(ecg_signals1.T):\n",
    "    ax[row,col].plot(x, sig)\n",
    "    ax[row,col].fill_between(x, np.min(sig), np.max(sig), where=(segmentation1[0,:] == 1), color='C0', alpha = 0.3 )\n",
    "    ax[row,col].fill_between(x, np.min(sig), np.max(sig), where=(segmentation1[1,:] == 1), color='C1', alpha = 0.3 )\n",
    "    ax[row,col].fill_between(x, np.min(sig), np.max(sig), where=(segmentation1[2,:] == 1), color='C2', alpha = 0.3 )\n",
    "    col += 1\n",
    "    if col >= 3:\n",
    "        row += 1\n",
    "        col = 0\n",
    "    plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcdb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# # PLEASE HAVE FAITH THIS SHOULD WORK\n",
    "# una mica d'anims per sobreviure i fer aquest treball\n",
    "\n",
    "# %% [markdown]\n",
    "# We create a dataframe of the ecg signal for a random patient to test. We take its segmentation and the ecg signal in order to take the last qrs segment. \n",
    "\n",
    "# %%\n",
    "# Initialize a dictionary to store segmentation results\n",
    "segmentation_results = []\n",
    "\n",
    "# Extract only the first row (patient 1)\n",
    "row = df_leads_only.iloc[19654]\n",
    "patient_id = row['patient']\n",
    "ecg_signal = np.array(row['V6'])  # Extract the V6 lead signal\n",
    "fs = 1000  # Sampling frequency\n",
    "\n",
    "print(\"Processing patient:\", patient_id)\n",
    "\n",
    "# Preprocess the signal\n",
    "ecg_250 = sak.signal.interpolate.interp1d(ecg_signal, round(ecg_signal.shape[0] * 250 / fs), axis=0).T\n",
    "ecg_250 = sp.signal.filtfilt(*sp.signal.butter(2, fs_high / 250., 'high'), ecg_250, axis=-1)\n",
    "ecg_250 = sp.signal.filtfilt(*sp.signal.butter(2, fs_low / 250., 'low'), ecg_250, axis=-1)\n",
    "\n",
    "# Apply segmentation\n",
    "segmentation_250, time_QRS = predict_ecg(ecg_250, 250., models_ECG, normalize=True, filter=False)\n",
    "\n",
    "# Interpolate back to the original sampling frequency\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "segmentation = sak.signal.interpolate.interp1d(segmentation_250, ecg_signal.shape[0], axis=-1, kind=\"nearest\")\n",
    "\n",
    "# Store the results\n",
    "segmentation_results.append({\n",
    "    'patient': patient_id,\n",
    "    'lead': 'V6',\n",
    "    'segmentation': segmentation,\n",
    "    'time_QRS': time_QRS, \n",
    "    'ecg_signal': ecg_signal\n",
    "})\n",
    "\n",
    "# Convert the results into a DataFrame\n",
    "segmentation_results_df = pd.DataFrame(segmentation_results)\n",
    "display(segmentation_results_df)\n",
    "\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# We look for the indices of these last qrs segment, with the aim of finding the index where the R peak of the last QRS segment is located\n",
    "\n",
    "# %%\n",
    "# Función para extraer los índices del último QRS\n",
    "def find_last_qrs_indices(segmentation_triplet):\n",
    "    qrs_seg = np.array(segmentation_triplet[1])\n",
    "    ones_indices = np.where(qrs_seg == 1)[0]\n",
    "    if len(ones_indices) == 0:\n",
    "        return []\n",
    "    groups = np.split(ones_indices, np.where(np.diff(ones_indices) > 1)[0] + 1)\n",
    "    return groups[-1].tolist()\n",
    "\n",
    "# Aplicar para obtener los índices del último QRS\n",
    "segmentation_results_df[\"last_qrs_indices\"] = segmentation_results_df[\"segmentation\"].apply(find_last_qrs_indices)\n",
    "\n",
    "# Extraer la señal de esos índices\n",
    "segmentation_results_df[\"last_qrs_signal\"] = segmentation_results_df.apply(\n",
    "    lambda row: np.array(row[\"ecg_signal\"])[row[\"last_qrs_indices\"]]\n",
    "    if len(row[\"last_qrs_indices\"]) > 0 else np.nan,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "display(segmentation_results_df)\n",
    "\n",
    "# Exportar a CSV\n",
    "segmentation_results_df.to_csv(\"segmentation_results.csv\", index=False)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# now we try to plot the detected segmentation to try to see if the process has been done correctly. \n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pick one row to visualize\n",
    "row = segmentation_results_df.iloc[0]  # Change the index to pick a different example\n",
    "\n",
    "# Get patient ID and lead\n",
    "patient = row[\"patient\"]\n",
    "lead = row[\"lead\"]\n",
    "qrs_indices = row[\"last_qrs_indices\"]\n",
    "\n",
    "# Fetch the corresponding ECG signal\n",
    "ecg_row = df_leads_only.iloc[19654] #put the same one as above!!\n",
    "#ecg_row = df_leads_only[df_leads_only[\"patient\"] == patient].iloc[0]\n",
    "ecg_signal = np.array(ecg_row[lead])\n",
    "\n",
    "# Get QRS start and end\n",
    "if qrs_indices:\n",
    "    qrs_start = qrs_indices[0]\n",
    "    qrs_end = qrs_indices[-1]\n",
    "else:\n",
    "    print(\"No QRS complex detected.\")\n",
    "    qrs_start = qrs_end = None\n",
    "\n",
    "# Time axis (in seconds)\n",
    "fs = 1000  # sampling frequency\n",
    "time = np.arange(len(ecg_signal)) / fs\n",
    "\n",
    "# Plot ECG\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(time, ecg_signal, label='ECG Signal')\n",
    "if qrs_start is not None:\n",
    "    plt.plot(time[qrs_start], ecg_signal[qrs_start], 'ro', label='QRS Start')\n",
    "    plt.plot(time[qrs_end], ecg_signal[qrs_end], 'ro', label='QRS End')\n",
    "\n",
    "plt.title(f\"ECG Lead {lead} - Patient {patient}\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bf2de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# We see the segmentation is done correctly. Now we import the csv created with the segmentations done for all ecg signals\n",
    "\n",
    "# %%\n",
    "ecg = pickle.load(open('../segmentation_results.pkl', 'rb'))\n",
    "\n",
    "ecg = pd.DataFrame(ecg)\n",
    "display(ecg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c786ebf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# We choose to compute time shift with v6 reference as it is the lead closest to the left ventricle, which means that the R peak will be best detected.\n",
    "\n",
    "# %% [markdown]\n",
    "# In the next cell we compute the time shift that will need to be induced to our signal in order to obtain the last R peak perfectly at 2s.\n",
    "\n",
    "# %%\n",
    "def compute_time_shift(row):\n",
    "    qrs_indices = row['last_qrs_indices']\n",
    "    ecg_signal = row['ecg_signal']\n",
    "\n",
    "    if not qrs_indices or len(ecg_signal) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    qrs_values = ecg_signal[qrs_indices]\n",
    "    max_idx = np.argmax(np.abs(qrs_values))\n",
    "    max_ecg_index = qrs_indices[max_idx]\n",
    "\n",
    "    return 2 - (max_ecg_index / 1000)\n",
    "\n",
    "\n",
    "# %%\n",
    "# Aplicar la función a cada fila y guardar resultados en una nueva columna\n",
    "ecg['time_shift'] = ecg.apply(compute_time_shift, axis=1)\n",
    "\n",
    "# Mostrar resultados\n",
    "for idx, row in ecg.iterrows():\n",
    "    print(f\"Patient: {row['patient']}, Lead: {row['lead']}, Time shift: {row['time_shift']:.4f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c57949",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_shifted_ecg(ecg_df, patient_index, fs=1000):\n",
    "    \"\"\"\n",
    "    Plotea la señal ECG antes y después del desplazamiento temporal.\n",
    "    \n",
    "    Parámetros:\n",
    "        ecg_df: DataFrame con columnas 'ecg_signal' y 'time_shift'\n",
    "        patient_index: índice entero del paciente dentro del DataFrame\n",
    "        fs: frecuencia de muestreo (default 1000 Hz)\n",
    "    \"\"\"\n",
    "    row = ecg_df.iloc[patient_index]\n",
    "    signal = row['ecg_signal']\n",
    "    time_shift = row['time_shift']\n",
    "    patient_id = row['patient']\n",
    "    lead = row['lead']\n",
    "    \n",
    "    # Eje temporal original\n",
    "    t = np.arange(len(signal)) / fs\n",
    "\n",
    "    # Calcular desplazamiento en muestras\n",
    "    shift_samples = int(round(time_shift * fs))\n",
    "\n",
    "    # Aplicar desplazamiento\n",
    "    if shift_samples > 0:\n",
    "        shifted_signal = np.pad(signal, (shift_samples, 0), mode='constant',  constant_values=(signal[0],))[:len(signal)]\n",
    "    elif shift_samples < 0:\n",
    "        shifted_signal = np.pad(signal, (0, -shift_samples), mode='constant',  constant_values=(signal[-1],))[-shift_samples:]\n",
    "    else:\n",
    "        shifted_signal = signal.copy()\n",
    "\n",
    "    # Graficar\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(t, signal, label='Original', linewidth=1.5)\n",
    "    plt.plot(t, shifted_signal, label=f'Shifted ({time_shift:.3f} s)', linestyle='--')\n",
    "    plt.title(f'Patient {patient_id} - Lead {lead}\\nTime shift: {time_shift:.3f} s ({shift_samples} samples)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1d66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# Just to check if the shift is done correctly\n",
    "\n",
    "# %%\n",
    "plot_shifted_ecg(ecg, patient_index=0) \n",
    "plot_shifted_ecg(ecg, patient_index=23455)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53ce494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# We put a new column to the df_leads_only the time shift calculated\n",
    "\n",
    "# %%\n",
    "display(ecg.head())\n",
    "\n",
    "# %% [markdown]\n",
    "# Now we do a new dataframe with only the signals shifted\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "fs = 1000\n",
    "lead_columns = ['I', 'II', 'III', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "\n",
    "#Limpieza y merge\n",
    "ecg_unique = ecg[['patient', 'time_shift']].drop_duplicates(subset='patient')\n",
    "df_leads_only['patient'] = df_leads_only['patient'].astype(str)\n",
    "ecg_unique['patient'] = ecg_unique['patient'].astype(str)\n",
    "\n",
    "df_with_shift = df_leads_only.merge(ecg_unique, on='patient', how='left')\n",
    "assert 'time_shift' in df_with_shift.columns, \"❌ La columna 'time_shift' no está presente tras el merge\"\n",
    "\n",
    "# Función de shift\n",
    "def shift_row_leads(row):\n",
    "    shifted = {}\n",
    "    shift_samples = int(round(row['time_shift'] * fs))\n",
    "    for lead in lead_columns:\n",
    "        signal = row[lead]\n",
    "        if isinstance(signal, np.ndarray):\n",
    "            if shift_samples > 0:\n",
    "                shifted_signal = np.pad(signal, (shift_samples, 0), mode='constant', constant_values=(signal[0],))[:len(signal)]\n",
    "            elif shift_samples < 0:\n",
    "                shifted_signal = np.pad(signal, (0, -shift_samples), mode='constant', constant_values=(signal[-1],))[-shift_samples:]\n",
    "            else:\n",
    "                shifted_signal = signal.copy()\n",
    "        else:\n",
    "            shifted_signal = np.zeros(5000)  # Valor por defecto si hay error\n",
    "        shifted[lead] = shifted_signal\n",
    "    shifted['patient'] = row['patient']\n",
    "    return pd.Series(shifted)\n",
    "\n",
    "# Chunked processing\n",
    "n_chunks = 10\n",
    "df_chunks = np.array_split(df_with_shift, n_chunks)\n",
    "\n",
    "all_shifted = []\n",
    "for i, chunk in enumerate(df_chunks):\n",
    "    print(f\"🔄 Procesando chunk {i+1}/{n_chunks}...\")\n",
    "    shifted_chunk = chunk.apply(shift_row_leads, axis=1)\n",
    "    all_shifted.append(shifted_chunk)\n",
    "\n",
    "df_shifted = pd.concat(all_shifted, ignore_index=True)\n",
    "\n",
    "# Reordenar columnas: 'patient' primero\n",
    "cols = ['patient'] + [col for col in df_shifted.columns if col != 'patient']\n",
    "df_shifted = df_shifted[cols]\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "display(df_shifted.head())\n",
    "\n",
    "# %% [markdown]\n",
    "# We plot some of these new ignalsto check that the stored signal is correctly shifted\n",
    "\n",
    "# %%\n",
    "row = df_shifted.iloc[0]\n",
    "signal = row['V6']\n",
    "patient_id = row['patient']\n",
    "t = np.arange(len(signal)) / fs\n",
    "     \n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(t, signal, label='Original', linewidth=1.5)\n",
    "plt.title(f'Patient {patient_id}')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "row = df_shifted.iloc[14800]\n",
    "signal = row['V6']\n",
    "patient_id = row['patient']\n",
    "t = np.arange(len(signal)) / fs\n",
    "     \n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(t, signal, label='Original', linewidth=1.5)\n",
    "plt.title(f'Patient {patient_id}')\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# We see that it is correctly stored\n",
    "\n",
    "# %% [markdown]\n",
    "# Now we have to do a dataframe to store the samples divided by columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef75c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parámetros\n",
    "n_chunks = 30  # Puedes ajustarlo según tu RAM\n",
    "lead_columns = ['I', 'II', 'III', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6']\n",
    "sample_length = len(df_shifted.iloc[0]['I'])  # Asumimos todas las señales tienen igual longitud\n",
    "\n",
    "# Expansión por chunks con barra de progreso\n",
    "flat_chunks = []\n",
    "\n",
    "print(\"\\n Expandiendo señales en columnas...\")\n",
    "\n",
    "for i, chunk in enumerate(tqdm(np.array_split(df_shifted, n_chunks), desc=\"Chunks procesados\")):\n",
    "    expanded_rows = []\n",
    "\n",
    "    for _, row in chunk.iterrows():\n",
    "        flat_row = {'patient': row['patient']}\n",
    "        for lead in lead_columns:\n",
    "            signal = row[lead]\n",
    "            flat_row.update({f\"{lead}_{j}\": signal[j] for j in range(sample_length)})\n",
    "        expanded_rows.append(flat_row)\n",
    "\n",
    "    df_expanded = pd.DataFrame(expanded_rows)\n",
    "    flat_chunks.append(df_expanded)\n",
    "\n",
    "# Unir todos los chunks\n",
    "df_samples = pd.concat(flat_chunks, ignore_index=True)\n",
    "\n",
    "# Guardar a archivo pickle\n",
    "df_samples.to_pickle(\"ecg_flattened_samples.pkl\")\n",
    "print(\" Archivo guardado como 'ecg_flattened_samples.pkl'\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompBioMed25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
