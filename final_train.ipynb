{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77b4aa08",
   "metadata": {},
   "source": [
    "# Final training\n",
    "\n",
    "Now we will work on how to run to train the different models in order to obtain the one with the best results and opitmize it's parameters to have the best model with the best parameters\n",
    "\n",
    "To do so we will follow the next logic:\n",
    "\n",
    "* From the subset of all models, we will select the ones with\n",
    "  * The ones with maximum interpretability\n",
    "  * The ones with lowest inference\n",
    "\n",
    "* To optimize their parameters, we will probably run some optimaztion technique, e.g. GD, or CGD, or an interative method, if the matrix is to large, and therefore finding the exact solution is not an option.\n",
    "\n",
    "\n",
    "In this notebook we will work on the assumption that we have already pre-processed all the data and we receive as input a matrix X containing all ECGs + demographic data and a matrix Y containing the final labels of the train, and we can divide them between train and test accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17b47e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (400, 110)\n",
      "X_test shape: (100, 110)\n",
      "Y_train shape: (400,)\n",
      "Y_test shape: (100,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4162/1593222527.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[f'ECG_{i}'] = np.random.normal(0, 1, n_samples)\n",
      "/tmp/ipykernel_4162/1593222527.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Gender'] = np.random.choice(['Male', 'Female'], n_samples)\n",
      "/tmp/ipykernel_4162/1593222527.py:24: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Smoker'] = np.random.choice(['Yes', 'No'], n_samples)\n",
      "/tmp/ipykernel_4162/1593222527.py:25: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['HTA'] = np.random.choice(['Yes', 'No'], n_samples)\n",
      "/tmp/ipykernel_4162/1593222527.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['DM'] = np.random.choice(['Yes', 'No'], n_samples)\n",
      "/tmp/ipykernel_4162/1593222527.py:27: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['DLP'] = np.random.choice(['Yes', 'No'], n_samples)\n",
      "/tmp/ipykernel_4162/1593222527.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['COPD'] = np.random.choice(['Yes', 'No'], n_samples)\n",
      "/tmp/ipykernel_4162/1593222527.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Sleep_apnea'] = np.random.choice(['Yes', 'No'], n_samples)\n",
      "/tmp/ipykernel_4162/1593222527.py:32: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df['Label'] = np.random.choice([0, 1], n_samples)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Parameters for synthetic data\n",
    "n_samples = 500\n",
    "n_ecg_features = 100  # e.g., ECG_0, ECG_1, ..., ECG_99\n",
    "\n",
    "# Create synthetic numeric columns\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame({\n",
    "    'Height': np.random.normal(170, 10, n_samples),\n",
    "    'Weight': np.random.normal(70, 15, n_samples),\n",
    "    'BMI': np.random.normal(24, 4, n_samples),\n",
    "})\n",
    "\n",
    "# Add synthetic ECG features\n",
    "for i in range(n_ecg_features):\n",
    "    df[f'ECG_{i}'] = np.random.normal(0, 1, n_samples)\n",
    "\n",
    "# Add categorical/boolean columns\n",
    "df['Gender'] = np.random.choice(['Male', 'Female'], n_samples)\n",
    "df['Smoker'] = np.random.choice(['Yes', 'No'], n_samples)\n",
    "df['HTA'] = np.random.choice(['Yes', 'No'], n_samples)\n",
    "df['DM'] = np.random.choice(['Yes', 'No'], n_samples)\n",
    "df['DLP'] = np.random.choice(['Yes', 'No'], n_samples)\n",
    "df['COPD'] = np.random.choice(['Yes', 'No'], n_samples)\n",
    "df['Sleep_apnea'] = np.random.choice(['Yes', 'No'], n_samples)\n",
    "\n",
    "# Add a binary label column\n",
    "df['Label'] = np.random.choice([0, 1], n_samples)\n",
    "\n",
    "# Now proceed as before\n",
    "Y = df['Label'].values\n",
    "\n",
    "numeric_cols = ['Height', 'Weight', 'BMI'] + [col for col in df.columns if col.startswith('ECG_')]\n",
    "X_numeric = df[numeric_cols].copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_numeric_scaled = pd.DataFrame(scaler.fit_transform(X_numeric), columns=X_numeric.columns, index=X_numeric.index)\n",
    "\n",
    "categorical_cols = ['Gender', 'Smoker', 'HTA', 'DM', 'DLP', 'COPD', 'Sleep_apnea']\n",
    "X_categorical = df[categorical_cols].copy()\n",
    "X_categorical_encoded = pd.get_dummies(X_categorical, drop_first=True)\n",
    "\n",
    "X = pd.concat([X_numeric_scaled, X_categorical_encoded], axis=1)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompBioMed25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
