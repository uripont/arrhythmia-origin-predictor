{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef60ef33",
   "metadata": {},
   "source": [
    "# An interpretable prediction system for the Site Of Origin (SOO) of Outflow Tract Ventricular Arrhythmias (OTVAs)\n",
    "\n",
    "## 0. Starting point\n",
    "\n",
    "See first the [README](README.md) for a general introduction to the project. We will start analyzing what we have as input, and how will we approach the tasks given our restrictions (dataset, interpretability, fast inference).\n",
    "\n",
    "### 0.1. About the dataset\n",
    "\n",
    "We were provided with a dataset with anonymous data from Teknon Medical Center, Barcelona, Spain. As explained in the [release](https://github.com/uripont/arrhythmia-origin-predictor/releases/download/dataset/dataset_arrhythmias.zip), the dataset contains electrocardiogram (ECG) recordings and demographic information from patients with Outflow Tract Ventricular Arrhythmias (OTVAs). Each case includes several 12-lead ECG signal segment (of 2.5 seconds), patient demographic data (age, sex, height, weight,...), and clinician-validated labels indicating the arrhythmia's Site of Origin (SOO). The SOO labels include Left Ventricular Outflow Tract (LVOT), Right Ventricular Outflow Tract (RVOT), and for LVOT cases, further classification into Right Coronary Cusp (RCC) or aortomitral commissure origins among others. \n",
    "\n",
    "The following code retrieves the dataset from the release and unzips it into `dataset/` folder, from which we will later load the data and perform the preprocessing. This allows 1:1 reproducibility of the results by performing this notebook's logic on the same input data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68f26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library packages:\n",
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# Third-party packages:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#TODO: add missing here and on requirements.txt\n",
    "\n",
    " \n",
    "# If running this notebook produces import errors, please install missing packages:\n",
    "# pip install -r requirements.txt\n",
    "# \n",
    "# Consider using a virtual environment:\n",
    "# python -m venv venv\n",
    "# source venv/bin/activate  # On Windows: venv\\Scripts\\activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37af894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the dataset zip file\n",
    "dataset_url = \"https://github.com/uripont/arrhythmia-origin-predictor/releases/download/dataset/dataset_arrhythmias.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a07448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset zip file already exists at dataset_arrhythmias.zip\n",
      "Extracting files to dataset/\n",
      "Dataset is ready in the 'dataset' directory.\n"
     ]
    }
   ],
   "source": [
    "# Local paths\n",
    "zip_path = \"dataset_arrhythmias.zip\"\n",
    "extract_dir = \"dataset\"\n",
    "\n",
    "# Create dataset directory if it doesn't exist\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Download the zip file\n",
    "if not os.path.exists(zip_path):\n",
    "    print(f\"Downloading dataset from {dataset_url}...\")\n",
    "    urllib.request.urlretrieve(dataset_url, zip_path)\n",
    "    print(f\"Download complete. Saved to {zip_path}\")\n",
    "else:\n",
    "    print(f\"Dataset zip file already exists at {zip_path}\")\n",
    "\n",
    "# Extract the contents\n",
    "print(f\"Extracting files to {extract_dir}/\")\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "print(f\"Dataset is ready in the '{extract_dir}' directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e25e899",
   "metadata": {},
   "source": [
    "### 0.2. Patient cases\n",
    "\n",
    "## 1. Our approach\n",
    "\n",
    "## 2. Demographic data preprocessing\n",
    "\n",
    "## 3. ECG signal preprocessing\n",
    "\n",
    "## 4. Model A: Dimensionality reduction for ECG signals\n",
    "\n",
    "## 5. Interpreting Model A\n",
    "\n",
    "## 5. Preparing data for training for the two tasks\n",
    "\n",
    "## 6. Model B: Classification of the SOO\n",
    "\n",
    "## 7. Interpreting Model B\n",
    "\n",
    "## 8. Model C: Classification of the sub-regions\n",
    "\n",
    "## 9. Interpreting Model C\n",
    "\n",
    "## 10. Final model evaluation and exporting for inference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
